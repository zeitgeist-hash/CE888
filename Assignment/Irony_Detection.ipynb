{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Irony Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhp6GG1qZMks"
      },
      "source": [
        "### Irony Detection\n",
        "\n",
        "ERNIE 2.0 is a continual pre-training framework proposed by Baidu in 2019, which builds and learns incrementally pre-training tasks through constant multi-task learning.\n",
        "This project will convert ERNIE to huggingface's format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB-trh1KZTtn"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRBY6XA4YtXQ",
        "outputId": "442b78e2-b247-4895-982f-ab62ae9c7031"
      },
      "source": [
        "pip install paddlepaddle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (3.12.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->paddlepaddle) (56.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1FpdIeNW5Dr",
        "outputId": "89092433-f703-4a25-f40e-ddcad817b49e"
      },
      "source": [
        "pip install paddle-ernie"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: paddle-ernie in /usr/local/lib/python3.7/dist-packages (0.1.0.dev1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from paddle-ernie) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddle-ernie) (4.41.1)\n",
            "Requirement already satisfied: pathlib2 in /usr/local/lib/python3.7/dist-packages (from paddle-ernie) (2.3.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2->paddle-ernie) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J3KEz-juCY-"
      },
      "source": [
        "pip install --upgrade paddlenlp>=2.0.0rc -i https://pypi.org/simple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VzU-GBo9jTE",
        "outputId": "89457b84-57f0-48bf-943b-9116fe0f9e35"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-o93hCPsE-M",
        "outputId": "d79125e5-f8fb-4dd5-e002-541f5a1bba51"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuwlFMk5QUcr",
        "outputId": "b90064de-1f8b-4c19-9c6e-33221d371944"
      },
      "source": [
        "import torch\n",
        "import paddle\n",
        "import paddlenlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from ernie.modeling_ernie import ErnieModel\n",
        "from ernie.tokenizing_ernie import ErnieTokenizer\n",
        "from ernie.modeling_ernie import ErnieModelForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/packaging/version.py:130: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\n",
            "  DeprecationWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRVOwaCCpcY7"
      },
      "source": [
        "# Load pre-trained ERNIE 2.0 model and ERNIE tokenizer.\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nghuyong/ernie-2.0-en\")\n",
        "\n",
        "model = AutoModel.from_pretrained(\"nghuyong/ernie-2.0-en\", return_dict=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zRZrZLIhXSx"
      },
      "source": [
        "### Data Exploration\n",
        "\n",
        "We will load the irony dataset from TweetEval to evaluate ERNIE 2.0 model. The irony dataset has already been split into training set, tuning set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MZZ9VZsUacJ"
      },
      "source": [
        "df_train_text = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/irony/train_text.txt\", delimiter=\"\\t\", names=[\"Tweet\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsAiVPzHUa-4"
      },
      "source": [
        "df_train_label = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/irony/train_labels.txt\", delimiter=\"\\t\", names=[\"Label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cJ1cjplbUbBc",
        "outputId": "58a90245-5bfe-41dd-b01b-3a85f06938ec"
      },
      "source": [
        "df_train = df_train_text.join(df_train_label)\n",
        "df_train.to_csv(\"train.csv\", encoding='utf-8', index=False)\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seeing ppl walking w/ crutches makes me really...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>look for the girl with the broken smile, ask h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Now I remember why I buy books online @user #s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user So is he banded from wearing the c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just found out there are Etch A Sketch apps.  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2857</th>\n",
              "      <td>I don't have to respect your beliefs.||I only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2858</th>\n",
              "      <td>Women getting hit on by married managers at @u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2859</th>\n",
              "      <td>@user no but i followed you and i saw you post...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2860</th>\n",
              "      <td>@user I dont know what it is but I'm in love y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>@user @user @user For having union representat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2862 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tweet  Label\n",
              "0     seeing ppl walking w/ crutches makes me really...      1\n",
              "1     look for the girl with the broken smile, ask h...      0\n",
              "2     Now I remember why I buy books online @user #s...      1\n",
              "3     @user @user So is he banded from wearing the c...      1\n",
              "4     Just found out there are Etch A Sketch apps.  ...      1\n",
              "...                                                 ...    ...\n",
              "2857  I don't have to respect your beliefs.||I only ...      0\n",
              "2858  Women getting hit on by married managers at @u...      1\n",
              "2859  @user no but i followed you and i saw you post...      0\n",
              "2860  @user I dont know what it is but I'm in love y...      0\n",
              "2861  @user @user @user For having union representat...      1\n",
              "\n",
              "[2862 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z956FCSysMiZ"
      },
      "source": [
        "df_val_text = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/irony/val_text.txt\", delimiter=\"\\t\", names=[\"Tweet\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXG2ex84sMu5"
      },
      "source": [
        "df_val_label = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/irony/val_labels.txt\", delimiter=\"\\t\", names=[\"Label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Vk-UqGjRsNRk",
        "outputId": "1c3cb9b0-ea75-41ab-ec81-225e0fe68467"
      },
      "source": [
        "df_val = df_val_text.join(df_val_label)\n",
        "df_val.to_csv(\"val.csv\", encoding='utf-8', index=False)\n",
        "df_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#NBA players #NY support protests of #police k...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A new year about to start|So many people came ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Obama's $1,176,120.90 in Taxpayer Funded Cost...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can't wait to work with the dream team again t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>!!! RT @user Of all the places to get stuck in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>950</th>\n",
              "      <td>Abraham was actually from modern day Iraq (Ur ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>@user which one is more disturbing dan? Tickli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>@user @user haha that's cool! I had a feeling ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>@user @user Let the Western bastards bank acco...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>FALSE, slavery was based on economics, @user @...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>955 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Tweet  Label\n",
              "0    #NBA players #NY support protests of #police k...      1\n",
              "1    A new year about to start|So many people came ...      0\n",
              "2     Obama's $1,176,120.90 in Taxpayer Funded Cost...      1\n",
              "3    Can't wait to work with the dream team again t...      1\n",
              "4    !!! RT @user Of all the places to get stuck in...      1\n",
              "..                                                 ...    ...\n",
              "950  Abraham was actually from modern day Iraq (Ur ...      0\n",
              "951  @user which one is more disturbing dan? Tickli...      1\n",
              "952  @user @user haha that's cool! I had a feeling ...      0\n",
              "953  @user @user Let the Western bastards bank acco...      1\n",
              "954  FALSE, slavery was based on economics, @user @...      0\n",
              "\n",
              "[955 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huvaiBrVcHUQ"
      },
      "source": [
        "df_test_text = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/irony/test_text.txt\", delimiter=\"\\t\", names=[\"Tweet\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcGxSie2VKCZ"
      },
      "source": [
        "df_test_label = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/irony/test_labels.txt\", delimiter=\"\\t\", names=[\"Label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "lXNaiomvVcpe",
        "outputId": "e6368c20-8c5b-4eb1-94a3-2b2aefb902fb"
      },
      "source": [
        "df_test = df_test_text.join(df_test_label)\n",
        "df_test.to_csv(\"test.csv\", encoding='utf-8', index=False)\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Can U Help?||More conservatives needed o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#NOT GONNA WIN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user He is exactly that sort of person. Weirdo!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So much #sarcasm at work mate 10/10 #boring 10...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>If you drag yesterday into today, your tomorro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>Congrats to my fav @user &amp; her team &amp; my birth...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>@user Jessica sheds tears at her fan signing e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>#Irony: al jazeera is pro Anti - #GamerGate be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>#NOT ALL 👌 There good &amp; bad in every occupatio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Tweet  Label\n",
              "0    @user Can U Help?||More conservatives needed o...      0\n",
              "1    Just walked in to #Starbucks and asked for a \"...      1\n",
              "2                                      #NOT GONNA WIN       0\n",
              "3    @user He is exactly that sort of person. Weirdo!       0\n",
              "4    So much #sarcasm at work mate 10/10 #boring 10...      1\n",
              "..                                                 ...    ...\n",
              "779  If you drag yesterday into today, your tomorro...      0\n",
              "780  Congrats to my fav @user & her team & my birth...      0\n",
              "781  @user Jessica sheds tears at her fan signing e...      0\n",
              "782  #Irony: al jazeera is pro Anti - #GamerGate be...      1\n",
              "783  #NOT ALL 👌 There good & bad in every occupatio...      0\n",
              "\n",
              "[784 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPo91oLyIH97",
        "outputId": "622bf4e4-ad60-4ca3-e4a7-4bb3b62e6e75"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2862, 2), (955, 2), (784, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "14qKPO-FTN6F",
        "outputId": "c665d4ab-4323-42b6-882e-51cf1ad8adab"
      },
      "source": [
        "# Training set\n",
        "\n",
        "sns.countplot(df_train['Label'])\n",
        "plt.xlabel('label class')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'label class')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "gmaEeARGTqL7",
        "outputId": "6f556dca-a7fc-44f4-fd1e-2a5d99ebfbd0"
      },
      "source": [
        "# Validation set\n",
        "\n",
        "sns.countplot(df_val['Label'])\n",
        "plt.xlabel('label class')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'label class')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "_j_WQPPXTr8R",
        "outputId": "0bc0c7ab-d15f-47b9-afe3-aba9f526687e"
      },
      "source": [
        "# Test set\n",
        "\n",
        "sns.countplot(df_test['Label'])\n",
        "plt.xlabel('label class')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'label class')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jMwA9sPkh5V"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "- Add special tokens to separate sentences and do classification\n",
        "- Pass sequences of constant length (introduce padding)\n",
        "- Create array of 0s (pad token) and 1s (real token) called *attention mask*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbzUI_IWgG3m"
      },
      "source": [
        "# Use this sample text from training set to understand the tokenization process:\n",
        "\n",
        "sample_text = df_train['Tweet'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdR6mbwwdEea",
        "outputId": "723b98fc-8a32-48ca-bb7c-4df1e735f25f"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_text,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True, # Add '[PAD]'\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt', # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ul1y8gvhJ_I",
        "outputId": "ea30f148-b459-411d-8711-c4a15b981a52"
      },
      "source": [
        "# Inverse the tokenization to have a look at the special tokens:\n",
        "\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'seeing',\n",
              " 'pp',\n",
              " '##l',\n",
              " 'walking',\n",
              " 'w',\n",
              " '/',\n",
              " 'cr',\n",
              " '##ut',\n",
              " '##ches',\n",
              " 'makes',\n",
              " 'me',\n",
              " 'really',\n",
              " 'excited',\n",
              " 'for',\n",
              " 'the',\n",
              " 'next',\n",
              " '3',\n",
              " 'weeks',\n",
              " 'of',\n",
              " 'my',\n",
              " 'life',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ChJbDlbdBhK",
        "outputId": "298bba1c-d645-438e-99da-826e618ee035"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  3773,  4903,  2140,  3788,  1059,  1013, 13675,  4904,  8376,\n",
              "         3084,  2033,  2428,  7568,  2005,  1996,  2279,  1017,  3134,  1997,\n",
              "         2026,  2166,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ8_oQrKdCqD",
        "outputId": "25d751a3-9b44-4902-f303-d358d48dc2af"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFXGNn_6lhYH"
      },
      "source": [
        "### Choosing Sequence Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUXs4-AZEo-_"
      },
      "source": [
        "# Store the token length of each tweet:\n",
        "\n",
        "token_lens = []\n",
        "\n",
        "for tweet in df_train['Tweet']:\n",
        "  tokens = tokenizer.encode(tweet)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "NwtwX0wJ2EA3",
        "outputId": "f73ea796-a533-40fd-8469-037eb492d2c5"
      },
      "source": [
        "# Plot the distribution:\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 100]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDru6wt3aChI"
      },
      "source": [
        "# Most of the tweet seem to contain less than 60 tokens, but we'll be on the safe side and choose a maximum length of 64.\n",
        "\n",
        "MAX_LEN = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAUCWbbDE1-r"
      },
      "source": [
        "# Create a PyTorch dataset:\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, targets, tokenizer, max_len):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    tweet = str(self.tweets[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'tweet_text': tweet,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzr9PifILOa"
      },
      "source": [
        "# Create data loader function:\n",
        "\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = TweetDataset(\n",
        "    tweets=df['Tweet'].to_numpy(),\n",
        "    targets=df['Label'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kmJTNWRIaVV",
        "outputId": "a4c0f827-1c08-4f45-fd1f-9203df73849a"
      },
      "source": [
        "# Choose a proper batch size and apply the data loader function to training data, validation data and test data:\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKFgVNSRIeNx",
        "outputId": "a2fe5895-0841-43c9-959f-a939bbe1e5c6"
      },
      "source": [
        "# Have a look at an example batch from our training data loader:\n",
        "\n",
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atulf3ZEIkae",
        "outputId": "645a72a7-63e5-4808-c825-54b55a1786a6"
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64])\n",
            "torch.Size([16, 64])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3p8swfQmhPw"
      },
      "source": [
        "### Sentiment Classification with ERNIE 2.0 and Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2j2-IfTIqkV"
      },
      "source": [
        "# The last_hidden_state is a sequence of hidden states of the last layer of the model. Obtaining the pooled_output is done by applying the ERNIE Pooler on last_hidden_state:\n",
        "\n",
        "last_hidden_state, pooled_output = model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JC1V_bkIyB_",
        "outputId": "e7a14fab-03a0-480f-fde2-6562b4c1f970"
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoibH_nUJWRD",
        "outputId": "38889396-f4bf-46b4-99f5-0a22981e1779"
      },
      "source": [
        "model.config.hidden_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mAOlPzZJXNz",
        "outputId": "0e4cd455-6140-4d92-8d6c-b9534d072bab"
      },
      "source": [
        "pooled_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jVm3mCJXxC"
      },
      "source": [
        "# We use all of the previous knowledge to create a sentiment classifier that uses ERNIE 2.0 model:\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.ernie = AutoModel.from_pretrained(\"nghuyong/ernie-2.0-en\", return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.ernie.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.ernie(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficDwxuCLBde"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6-nfyyfKq_9"
      },
      "source": [
        "class_names = ['non_irony', 'irony']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7LShQXoJfpj"
      },
      "source": [
        "# Create an instance and move it to the Colab GPU:\n",
        "\n",
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPQNWvlEK4ir",
        "outputId": "1877ff90-378a-4a4e-81ea-18b7072c4772"
      },
      "source": [
        "# Move the example batch of our training data to the Colab GPU:\n",
        "\n",
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64])\n",
            "torch.Size([16, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFtM_A19LIPJ",
        "outputId": "2333d64d-679e-4a4f-a57f-d4b1a3aa28b6"
      },
      "source": [
        "model(input_ids, attention_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.6147e-01, -6.4026e-02],\n",
              "        [-1.8124e-01,  2.8659e-01],\n",
              "        [-3.3938e-01,  4.0284e-01],\n",
              "        [-4.7173e-01, -2.7690e-01],\n",
              "        [-3.4634e-01,  3.4095e-01],\n",
              "        [-4.0740e-01,  1.2078e-01],\n",
              "        [-6.8855e-01,  4.0966e-02],\n",
              "        [-4.6730e-01,  3.8378e-01],\n",
              "        [-2.8715e-01, -7.4462e-04],\n",
              "        [-2.5038e-01, -3.7775e-02],\n",
              "        [-3.3014e-01,  3.1184e-02],\n",
              "        [-4.3643e-01, -1.3785e-01],\n",
              "        [-1.3118e-01,  1.7981e-01],\n",
              "        [ 5.1298e-02,  9.1248e-01],\n",
              "        [-1.2792e-01,  8.6951e-02],\n",
              "        [ 4.5835e-02,  3.1749e-01]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIastka-nXTV"
      },
      "source": [
        "### Model training\n",
        " \n",
        "Although our datasets are small, we set the hyperparameters (batch size, learning rate and number of epoch) at reasonable values in order to avoid over-fitting and to obtain high prediction accuracy. We use the AdamW optimizer provided by Hugging Face that could correct weight decay. We also use a linear scheduler with no warmup steps.\n",
        "\n",
        "- Optimizer: AdamW\n",
        "- Batch size: 16\n",
        "- Learning rate : 2e-5\n",
        "- Number of epochs: 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOKZkx1SMLbj"
      },
      "source": [
        "# Set up epochs, optimizer and scheduler:\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyXbuHUfTmSO"
      },
      "source": [
        "# A helper function for training our model for one epoch:\n",
        "\n",
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNgWx_kFTNaF"
      },
      "source": [
        "# Another helper function that helps us evaluate the model on a given data loader:\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mF5T6H4T4qN",
        "outputId": "60543c50-053b-4c0b-9aab-dd4ef63690da"
      },
      "source": [
        "# Using those two helper functions, we can write our training loop. We'll also store the training history:\n",
        "\n",
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.6572809304271996 accuracy 0.6146051712089448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.600380597015222 accuracy 0.6785340314136127\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.46428549069099584 accuracy 0.7962962962962963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.7708405191699664 accuracy 0.7099476439790576\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.271278427716074 accuracy 0.8983228511530398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.1651799860099952 accuracy 0.6837696335078535\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1736757067804792 accuracy 0.9514325646401117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.4125236098965008 accuracy 0.7026178010471205\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.12280728749140014 accuracy 0.9671558350803633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.4581599767009417 accuracy 0.7068062827225131\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.0553733322843545 accuracy 0.9870719776380154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.8087158113718034 accuracy 0.7036649214659687\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.03633593701284025 accuracy 0.9930118798043326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.9113725215196609 accuracy 0.6942408376963352\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.02046823944891907 accuracy 0.9958071278825995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.9590738932291667 accuracy 0.7099476439790576\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.012305317320743856 accuracy 0.9975541579315164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 2.11509470641613 accuracy 0.6942408376963352\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.009947256248524964 accuracy 0.9979035639412998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 2.0854244470596313 accuracy 0.7005235602094242\n",
            "\n",
            "CPU times: user 4min 9s, sys: 2min 53s, total: 7min 2s\n",
            "Wall time: 7min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "YqjE6UBaUD0g",
        "outputId": "0a3c3109-941d-4da6-e473-889855ebbad2"
      },
      "source": [
        "# Plot the training accuracy and validation accuracy of each epoch:\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history (Irony Detection)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIMAdCz4pfas"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Calculating the accuracy on our test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3w26Ooim-_",
        "outputId": "b78e6e15-b8cc-46ca-d39e-fbff652c0fdb"
      },
      "source": [
        "# Calculating the accuracy on the test set:\n",
        "\n",
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7066326530612245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775k6ZTalu2-"
      },
      "source": [
        "# Define a helper function to get the predictions from our model:\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  tweet_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"tweet_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      tweet_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(targets)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return tweet_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In4t-Tc3mF4O",
        "outputId": "d4d3e0ee-4097-451d-88ae-5729148fd40b"
      },
      "source": [
        "# Storing the text of tweets and predicted probabilities:\n",
        "\n",
        "y_tweet_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAWZwMjjmIbM",
        "outputId": "72f7150b-fc5d-4aee-d310-cd56fbe4ed05"
      },
      "source": [
        "# Print the classification report:\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   non_irony       0.83      0.65      0.73       473\n",
            "       irony       0.60      0.80      0.68       311\n",
            "\n",
            "    accuracy                           0.71       784\n",
            "   macro avg       0.71      0.72      0.71       784\n",
            "weighted avg       0.74      0.71      0.71       784\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "_RLU8dE9mUrI",
        "outputId": "c8f920ad-63dc-44f3-f786-370107d4cbea"
      },
      "source": [
        "# Plot the confusion matrix:\n",
        "\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment (Irony Detection)');\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hQTQaecmYuA"
      },
      "source": [
        "# Check an example tweet from the test set:\n",
        "\n",
        "idx = 2\n",
        "tweet_text = y_tweet_texts[idx]\n",
        "true_sentiment = y_test[idx]\n",
        "pred_df = pd.DataFrame({\n",
        "  'class_names': class_names,\n",
        "  'values': y_pred_probs[idx]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXS_1enbmfWX",
        "outputId": "857fae8d-9463-47ab-e6a9-32ae982f158d"
      },
      "source": [
        "print(\"\\n\".join(wrap(tweet_text)))\n",
        "print()\n",
        "print(f'True sentiment: {class_names[true_sentiment]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#NOT GONNA WIN\n",
            "\n",
            "True sentiment: non_irony\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "1Bk3_bfpoKlQ",
        "outputId": "7a6d8924-2e27-41ac-9a7e-92550dc9b828"
      },
      "source": [
        "# Look at the confidence of each sentiment of our model:\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
        "plt.ylabel('sentiment')\n",
        "plt.xlabel('probability')\n",
        "plt.xlim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyGgOJhRovY-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}