{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOF4XHU8btZN"
      },
      "source": [
        "### Emotion Recognition\n",
        "\n",
        "ERNIE 2.0 is a continual pre-training framework proposed by Baidu in 2019, which builds and learns incrementally pre-training tasks through constant multi-task learning.\n",
        "This project will convert ERNIE to huggingface's format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB-trh1KZTtn"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRBY6XA4YtXQ",
        "outputId": "2baef065-1d2d-41a3-e7c2-9dc5307cb4cb"
      },
      "source": [
        "pip install paddlepaddle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (3.12.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.19.5)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->paddlepaddle) (56.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1FpdIeNW5Dr",
        "outputId": "faee4391-54f5-4ba6-ef0d-0704553bd289"
      },
      "source": [
        "pip install paddle-ernie"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: paddle-ernie in /usr/local/lib/python3.7/dist-packages (0.1.0.dev1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from paddle-ernie) (2.23.0)\n",
            "Requirement already satisfied: pathlib2 in /usr/local/lib/python3.7/dist-packages (from paddle-ernie) (2.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddle-ernie) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->paddle-ernie) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2->paddle-ernie) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J3KEz-juCY-"
      },
      "source": [
        "pip install --upgrade paddlenlp>=2.0.0rc -i https://pypi.org/simple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VzU-GBo9jTE",
        "outputId": "75aa1121-e3c9-4c8e-dd1d-622f1257c0aa"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-o93hCPsE-M",
        "outputId": "37324290-6462-423d-fbd3-da1121006cb1"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuwlFMk5QUcr",
        "outputId": "c13cfef0-847d-4c73-f6ae-c82997edb650"
      },
      "source": [
        "import torch\n",
        "import paddle\n",
        "import paddlenlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from ernie.modeling_ernie import ErnieModel\n",
        "from ernie.tokenizing_ernie import ErnieTokenizer\n",
        "from ernie.modeling_ernie import ErnieModelForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/packaging/version.py:130: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\n",
            "  DeprecationWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRVOwaCCpcY7"
      },
      "source": [
        "# Load pre-trained ERNIE 2.0 model and ERNIE tokenizer.\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nghuyong/ernie-2.0-en\")\n",
        "\n",
        "model = AutoModel.from_pretrained(\"nghuyong/ernie-2.0-en\", return_dict=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zRZrZLIhXSx"
      },
      "source": [
        "### Data Exploration\n",
        "\n",
        "We will load the irony dataset from TweetEval to evaluate ERNIE 2.0 model. The irony dataset has already been split into training set, tuning set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvkQcbPbqR72"
      },
      "source": [
        "df_train_text = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/emotion/train_text.txt\", delimiter=\"\\t\", names=[\"Tweet\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWE3P7mmqR72"
      },
      "source": [
        "df_train_label = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/emotion/train_labels.txt\", delimiter=\"\\t\", names=[\"Label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7OQ6-ctWqR73",
        "outputId": "e76e84e2-684a-467b-9f48-c14159659cd3"
      },
      "source": [
        "df_train = df_train_text.join(df_train_label)\n",
        "df_train.to_csv(\"train.csv\", encoding='utf-8', index=False)\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>â€œWorry is a down payment on a problem you may ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3252</th>\n",
              "      <td>I get discouraged because I try for 5 fucking ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3253</th>\n",
              "      <td>The @user are in contention and hosting @user ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3254</th>\n",
              "      <td>@user @user @user @user @user as a fellow UP g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3255</th>\n",
              "      <td>You have a #problem? Yes! Can you do #somethin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>@user @user i will fight this guy! Don't insul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3257 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tweet  Label\n",
              "0     â€œWorry is a down payment on a problem you may ...      2\n",
              "1     My roommate: it's okay that we can't spell bec...      0\n",
              "2     No but that's so cute. Atsu was probably shy a...      1\n",
              "3     Rooneys fucking untouchable isn't he? Been fuc...      0\n",
              "4     it's pretty depressing when u hit pan on ur fa...      3\n",
              "...                                                 ...    ...\n",
              "3252  I get discouraged because I try for 5 fucking ...      3\n",
              "3253  The @user are in contention and hosting @user ...      3\n",
              "3254  @user @user @user @user @user as a fellow UP g...      0\n",
              "3255  You have a #problem? Yes! Can you do #somethin...      0\n",
              "3256  @user @user i will fight this guy! Don't insul...      0\n",
              "\n",
              "[3257 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVdnG6XhqR73"
      },
      "source": [
        "df_val_text = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/emotion/val_text.txt\", delimiter=\"\\t\", names=[\"Tweet\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neAWMcVMqR73"
      },
      "source": [
        "df_val_label = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/emotion/val_labels.txt\", delimiter=\"\\t\", names=[\"Label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Hdj2SL1vqR74",
        "outputId": "ad560fef-1c6c-48a1-bc81-3c15db5369ff"
      },
      "source": [
        "df_val = df_val_text.join(df_val_label)\n",
        "df_val.to_csv(\"val.csv\", encoding='utf-8', index=False)\n",
        "df_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user Oh, hidden revenge and anger...I r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>if not then #teamchristine bc all tana has don...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey @user #Fields in #skibbereen give your onl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why have #Emmerdale had to rob #robron of havi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user I would like to hear a podcast of you go...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>@user @user If #trump #whitehouse aren't held ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>@user Which #chutiya #producer #invested in #c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>Russia story will infuriate Trump today. Media...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>Shit getting me irritated ðŸ˜ </td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>@user @user If this didn't make me so angry, I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>374 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Tweet  Label\n",
              "0    @user @user Oh, hidden revenge and anger...I r...      0\n",
              "1    if not then #teamchristine bc all tana has don...      0\n",
              "2    Hey @user #Fields in #skibbereen give your onl...      0\n",
              "3    Why have #Emmerdale had to rob #robron of havi...      0\n",
              "4    @user I would like to hear a podcast of you go...      0\n",
              "..                                                 ...    ...\n",
              "369  @user @user If #trump #whitehouse aren't held ...      0\n",
              "370  @user Which #chutiya #producer #invested in #c...      0\n",
              "371  Russia story will infuriate Trump today. Media...      0\n",
              "372                       Shit getting me irritated ðŸ˜        0\n",
              "373  @user @user If this didn't make me so angry, I...      0\n",
              "\n",
              "[374 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyvOQVIqqR74"
      },
      "source": [
        "df_test_text = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/emotion/test_text.txt\", delimiter=\"\\t\", names=[\"Tweet\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpMgJGdQqR74"
      },
      "source": [
        "df_test_label = pd.read_csv(\"https://raw.githubusercontent.com/zeitgeist-hash/tweeteval/main/datasets/emotion/test_labels.txt\", delimiter=\"\\t\", names=[\"Label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cHqZqSNIqR74",
        "outputId": "9281c5e4-2c6c-4d69-e026-324b9b178b15"
      },
      "source": [
        "df_test = df_test_text.join(df_test_label)\n",
        "df_test.to_csv(\"test.csv\", encoding='utf-8', index=False)\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user Interesting choice of words... Are you c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My visit to hospital for care triggered #traum...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What makes you feel #joyful?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1416</th>\n",
              "      <td>I need a sparkling bodysuit . No occasion. Jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1417</th>\n",
              "      <td>@user I've finished reading it; simply mind-bl...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1418</th>\n",
              "      <td>shaft abrasions from panties merely shifted to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1419</th>\n",
              "      <td>All this fake outrage. Y'all need to stop ðŸ¤£</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>Would be ever so grateful if you could record ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1421 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tweet  Label\n",
              "0     #Deppression is real. Partners w/ #depressed p...      3\n",
              "1     @user Interesting choice of words... Are you c...      0\n",
              "2     My visit to hospital for care triggered #traum...      3\n",
              "3     @user Welcome to #MPSVT! We are delighted to h...      1\n",
              "4                         What makes you feel #joyful?       1\n",
              "...                                                 ...    ...\n",
              "1416  I need a sparkling bodysuit . No occasion. Jus...      1\n",
              "1417  @user I've finished reading it; simply mind-bl...      3\n",
              "1418  shaft abrasions from panties merely shifted to...      0\n",
              "1419       All this fake outrage. Y'all need to stop ðŸ¤£       0\n",
              "1420  Would be ever so grateful if you could record ...      1\n",
              "\n",
              "[1421 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPo91oLyIH97",
        "outputId": "23765500-4b93-4dfc-a194-33bd60cff2f6"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3257, 2), (374, 2), (1421, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "14qKPO-FTN6F",
        "outputId": "c9d95b0e-c8f9-415b-dfd0-a2915ecbb9f1"
      },
      "source": [
        "# Training set\n",
        "\n",
        "sns.countplot(df_train['Label'])\n",
        "plt.xlabel('label class')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'label class')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "gmaEeARGTqL7",
        "outputId": "082ed005-7696-4ccd-f4c2-8df9cc2a921f"
      },
      "source": [
        "# Validation set\n",
        "\n",
        "sns.countplot(df_val['Label'])\n",
        "plt.xlabel('label class')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'label class')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "_j_WQPPXTr8R",
        "outputId": "7e603e33-2bca-49c7-8f81-933f77730985"
      },
      "source": [
        "# Test set\n",
        "\n",
        "sns.countplot(df_test['Label'])\n",
        "plt.xlabel('label class')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'label class')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ00lEQVR4nO3dfbBdVX3G8e9DgvhaQXOLMQFjlWqpVoQ7FKX1jdER2hrqoOILpJZO2ikqaqctdjq1dWpHp1WrqHRSQYJSLRURaq1KkZdqRU0QAYnWlJGSTCRR3qQOtcFf/7gry0u4ITcv+557c7+fmT1n77XX2ed3zkCeu/Y+e51UFZIkAew36gIkSbOHoSBJ6gwFSVJnKEiSOkNBktQtHHUBe2LRokW1bNmyUZchSXPK2rVrv19VY1Ptm9OhsGzZMtasWTPqMiRpTklyy472efpIktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1M3pO5p35qg/PH/UJcwaa//61FGXIGkOcKQgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqBg2FJN9NckOS65KsaW2PSXJZku+0x4Nae5K8L8n6JNcnOXLI2iRJDzQTI4XnV9URVTXets8ELq+qw4DL2zbA8cBhbVkJnD0DtUmSJhnF6aPlwOq2vho4cVL7+TXhGuDAJItHUJ8kzVtDh0IBn0+yNsnK1nZwVW1q698DDm7rS4BbJz13Q2u7nyQrk6xJsmbLli1D1S1J89LCgY//K1W1McnPApcl+dbknVVVSWpXDlhVq4BVAOPj47v0XEnSgxt0pFBVG9vjZuBi4Gjgtm2nhdrj5tZ9I3DIpKcvbW2SpBkyWCgkeUSSR21bB14E3AhcCqxo3VYAl7T1S4FT27eQjgHumnSaSZI0A4Y8fXQwcHGSba/zD1X12SRfAy5MchpwC/Dy1v8zwAnAeuBHwGsHrE2SNIXBQqGqbgaeMUX7D4Djpmgv4PSh6pEk7Zx3NEuSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWDh0KSBUm+nuTTbfuJSb6SZH2Sf0zykNZ+QNte3/YvG7o2SdL9zcRI4Qxg3aTtdwLvqaonA3cAp7X204A7Wvt7Wj9J0gwaNBSSLAV+DfhQ2w7wAuATrctq4MS2vrxt0/Yf1/pLkmbI0COFvwX+CPhJ234scGdVbW3bG4AlbX0JcCtA239X638/SVYmWZNkzZYtW4asXZLmncFCIcmvA5urau3ePG5Vraqq8aoaHxsb25uHlqR5b+GAxz4WeEmSE4CHAj8DvBc4MMnCNhpYCmxs/TcChwAbkiwEHg38YMD6JEnbGWykUFVvqaqlVbUMOBn4QlW9GrgCOKl1WwFc0tYvbdu0/V+oqhqqPknSA43iPoU/Bt6cZD0T1wzOae3nAI9t7W8GzhxBbZI0rw15+qirqiuBK9v6zcDRU/S5F3jZTNQjSZqadzRLkroZGSlI0tCues5zR13CrPHcq6/a7ec6UpAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM6b1zRt//22p4+6hFnj0D+7YdQlSINwpCBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1E0rFJJcPp02SdLc9qCzpCZ5KPBwYFGSg4C0XT8DLBm4NknSDNvZ1Nm/C7wReDywlp+Gwt3A+wesS5I0Ag8aClX1XuC9SV5fVWfNUE2SpBGZ1o/sVNVZSZ4NLJv8nKo6f6C6JEkjMK1QSPIR4EnAdcB9rbmAHYZCux5xNXBAe51PVNVbkzwR+DjwWCZOSZ1SVT9OckA73lHAD4BXVNV3d+dNSZJ2z3R/jnMcOLyqaheO/b/AC6rqniT7A19M8q/Am4H3VNXHk/wdcBpwdnu8o6qenORk4J3AK3bh9SRJe2i69yncCDxuVw5cE+5pm/u3pYAXAJ9o7auBE9v68rZN239ckm0XtiVJM2C6I4VFwE1JvsrECACAqnrJgz0pyQImThE9GfgA8F/AnVW1tXXZwE+/2roEuLUdd2uSu5g4xfT97Y65ElgJcOihh06zfEnSdEw3FP58dw5eVfcBRyQ5ELgYeOruHGe7Y64CVgGMj4/vyuksSdJOTPfbR1ftyYtU1Z1JrgCeBRyYZGEbLSwFNrZuG4FDgA1JFgKPZuKCsyRphkx3mosfJrm7LfcmuS/J3Tt5zlgbIZDkYcALgXXAFcBJrdsK4JK2fmnbpu3/wi5e2JYk7aHpjhQetW29XfxdDhyzk6ctBla36wr7ARdW1aeT3AR8PMlfAl8Hzmn9zwE+kmQ9cDtw8i69E0nSHpvuNYWu/fX+qSRvBc58kH7XA8+cov1m4Ogp2u8FXrar9UiS9p7p3rz20kmb+zFx38K9g1QkSRqZ6Y4UfmPS+lbgu0ycQpIk7UOme03htUMXIkkavel++2hpkouTbG7LRUmWDl2cJGlmTXeaiw8z8ZXRx7fln1ubJGkfMt1QGKuqD1fV1racB4wNWJckaQSmGwo/SPKaJAva8hq821iS9jnTDYXfBl4OfA/YxMQdx781UE2SpBGZ7ldS3wasqKo7AJI8BvgbJsJCkrSPmO5I4Ze2BQJAVd3OFHcrS5LmtumGwn5JDtq20UYKuzxFhiRpdpvuP+zvAr6c5J/a9suAtw9TkiRpVKZ7R/P5SdYw8VOaAC+tqpuGK0uSNArTPgXUQsAgkKR92HSvKUiS5gFDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSd1goZDkkCRXJLkpyTeTnNHaH5PksiTfaY8HtfYkeV+S9UmuT3LkULVJkqY25EhhK/AHVXU4cAxwepLDgTOBy6vqMODytg1wPHBYW1YCZw9YmyRpCoOFQlVtqqpr2/oPgXXAEmA5sLp1Ww2c2NaXA+fXhGuAA5MsHqo+SdIDzcg1hSTLgGcCXwEOrqpNbdf3gIPb+hLg1klP29DaJEkzZPBQSPJI4CLgjVV19+R9VVVA7eLxViZZk2TNli1b9mKlkqRBQyHJ/kwEwgVV9cnWfNu200LtcXNr3wgcMunpS1vb/VTVqqoar6rxsbGx4YqXpHloyG8fBTgHWFdV756061JgRVtfAVwyqf3U9i2kY4C7Jp1mkiTNgIUDHvtY4BTghiTXtbY/Ad4BXJjkNOAW4OVt32eAE4D1wI+A1w5YmyRpCoOFQlV9EcgOdh83Rf8CTh+qHknSznlHsySpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkbuGoC5Dmq2PPOnbUJcwaX3r9l0ZdghpHCpKkzlCQJHWGgiSpMxQkSZ2hIEnqBguFJOcm2Zzkxkltj0lyWZLvtMeDWnuSvC/J+iTXJzlyqLokSTs25EjhPODF27WdCVxeVYcBl7dtgOOBw9qyEjh7wLokSTswWChU1dXA7ds1LwdWt/XVwImT2s+vCdcAByZZPFRtkqSpzfQ1hYOralNb/x5wcFtfAtw6qd+G1vYASVYmWZNkzZYtW4arVJLmoZFdaK6qAmo3nreqqsaranxsbGyAyiRp/prpULht22mh9ri5tW8EDpnUb2lrkyTNoJkOhUuBFW19BXDJpPZT27eQjgHumnSaSZI0QwabEC/Jx4DnAYuSbADeCrwDuDDJacAtwMtb988AJwDrgR8Brx2qLknSjg0WClX1yh3sOm6KvgWcPlQtkqTp8Y5mSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkblaFQpIXJ/l2kvVJzhx1PZI038yaUEiyAPgAcDxwOPDKJIePtipJml9mTSgARwPrq+rmqvox8HFg+YhrkqR5JVU16hoASHIS8OKq+p22fQrwy1X1uu36rQRWts2nAN+e0UJ3zyLg+6MuYh/i57n3+FnuXXPl83xCVY1NtWPhTFeyp6pqFbBq1HXsiiRrqmp81HXsK/w89x4/y71rX/g8Z9Ppo43AIZO2l7Y2SdIMmU2h8DXgsCRPTPIQ4GTg0hHXJEnzyqw5fVRVW5O8DvgcsAA4t6q+OeKy9pY5dbprDvDz3Hv8LPeuOf95zpoLzZKk0ZtNp48kSSNmKEiSOkNhQE7bsXclOTfJ5iQ3jrqWuS7JIUmuSHJTkm8mOWPUNc1lSR6a5KtJvtE+z78YdU27y2sKA2nTdvwn8EJgAxPfrnplVd000sLmsCTPAe4Bzq+qp426nrksyWJgcVVdm+RRwFrgRP/73D1JAjyiqu5Jsj/wReCMqrpmxKXtMkcKw3Hajr2sqq4Gbh91HfuCqtpUVde29R8C64Alo61q7qoJ97TN/dsyJ//iNhSGswS4ddL2BvyfTrNQkmXAM4GvjLaSuS3JgiTXAZuBy6pqTn6ehoI0jyV5JHAR8MaqunvU9cxlVXVfVR3BxGwMRyeZk6c4DYXhOG2HZrV27vsi4IKq+uSo69lXVNWdwBXAi0ddy+4wFIbjtB2atdqF0XOAdVX17lHXM9clGUtyYFt/GBNfMPnWaKvaPYbCQKpqK7Bt2o51wIX70LQdI5HkY8CXgack2ZDktFHXNIcdC5wCvCDJdW05YdRFzWGLgSuSXM/EH4SXVdWnR1zTbvErqZKkzpGCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQfNOknt2sn/Zrs7EmuS8JCdNs+8uH1+aKYaCJKkzFDRvJXlkksuTXJvkhiSTZ7FdmOSCJOuSfCLJw9tzjkpyVZK1ST7XpqB+sNd4cpJ/a/PsX5vkSdvtX5bk39u+a5M8u7UvTnJ1u6nsxiS/2iZcO69t35DkTXv9Q9G8ZyhoPrsX+M2qOhJ4PvCuNv0DwFOAD1bVLwB3A7/f5go6Czipqo4CzgXevpPXuAD4QFU9A3g2sGm7/ZuBF7YaXgG8r7W/Cvhcm2DtGcB1wBHAkqp6WlU9Hfjw7r5xaUcWjroAaYQC/FX78Z6fMDG1+cFt361V9aW2/lHgDcBngacBl7XsWMAD/5H/6cEnfrxmSVVdDFBV97b2yd32B96f5AjgPuDnW/vXgHNbEH2qqq5LcjPwc0nOAv4F+PwevHdpSo4UNJ+9GhgDjmp/kd8GPLTt237+l2IiRL5ZVUe05elV9aI9rOFN7XWfAYwDD4H+g0LPYWJm3fOSnFpVd7R+VwK/B3xoD19begBDQfPZo4HNVfV/SZ4PPGHSvkOTPKutv4qJn1f8NjC2rT3J/kl+cUcHb79otiHJia3/AduuTWxXw6aq+gkTE9QtaH2fANxWVX/PxD/+RyZZBOxXVRcBfwocuSdvXpqKoaD57AJgPMkNwKncf6rjbwOnJ1kHHASc3X5W9STgnUm+wcR5/mfv5DVOAd7QZs/8D+Bx2+3/ILCiHe+pwP+09ucB30jydSauNbyXidNbV7Zf9/oo8JZdf8vSg3OWVElS50hBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUvf/+UZGxxfv/DoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jMwA9sPkh5V"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "- Add special tokens to separate sentences and do classification\n",
        "- Pass sequences of constant length (introduce padding)\n",
        "- Create array of 0s (pad token) and 1s (real token) called *attention mask*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbzUI_IWgG3m"
      },
      "source": [
        "# Use this sample text from training set to understand the tokenization process:\n",
        "\n",
        "sample_text = df_train['Tweet'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdR6mbwwdEea",
        "outputId": "1c90b31c-4018-413d-a964-ba91b10b141d"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_text,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True, # Add '[PAD]'\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ul1y8gvhJ_I",
        "outputId": "78bf993b-5884-4838-b7d1-6e5fd3c12cdd"
      },
      "source": [
        "# Inverse the tokenization to have a look at the special tokens:\n",
        "\n",
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'â€œ',\n",
              " 'worry',\n",
              " 'is',\n",
              " 'a',\n",
              " 'down',\n",
              " 'payment',\n",
              " 'on',\n",
              " 'a',\n",
              " 'problem',\n",
              " 'you',\n",
              " 'may',\n",
              " 'never',\n",
              " 'have',\n",
              " \"'\",\n",
              " '.',\n",
              " 'joyce',\n",
              " 'meyer',\n",
              " '.',\n",
              " '#',\n",
              " 'motivation',\n",
              " '#',\n",
              " 'leadership',\n",
              " '#',\n",
              " 'worry',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ChJbDlbdBhK",
        "outputId": "23137da2-47a4-4d24-af64-726d5d9c5a35"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  1523,  4737,  2003,  1037,  2091,  7909,  2006,  1037,  3291,\n",
              "         2017,  2089,  2196,  2031,  1005,  1012, 11830, 11527,  1012,  1001,\n",
              "        14354,  1001,  4105,  1001,  4737,   102,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ8_oQrKdCqD",
        "outputId": "1a64035a-10c1-4d00-9ec8-920db885f60b"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFXGNn_6lhYH"
      },
      "source": [
        "### Choosing Sequence Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUXs4-AZEo-_"
      },
      "source": [
        "# Store the token length of each tweet:\n",
        "\n",
        "token_lens = []\n",
        "\n",
        "for tweet in df_train['Tweet']:\n",
        "  tokens = tokenizer.encode(tweet)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "NwtwX0wJ2EA3",
        "outputId": "a87bd94d-a163-49a5-e2db-8f3e78eb6412"
      },
      "source": [
        "# Plot the distribution:\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 100]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDru6wt3aChI"
      },
      "source": [
        "# Most of the tweet seem to contain less than 60 tokens, but we'll be on the safe side and choose a maximum length of 64.\n",
        "\n",
        "MAX_LEN = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAUCWbbDE1-r"
      },
      "source": [
        "# Create a PyTorch dataset:\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, targets, tokenizer, max_len):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    tweet = str(self.tweets[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'tweet_text': tweet,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzr9PifILOa"
      },
      "source": [
        "# Create data loader function:\n",
        "\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = TweetDataset(\n",
        "    tweets=df['Tweet'].to_numpy(),\n",
        "    targets=df['Label'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kmJTNWRIaVV",
        "outputId": "e174ee5e-0290-4ff1-efa9-e201e85ad89a"
      },
      "source": [
        "# Choose a proper batch size and apply the data loader function to training data, validation data and test data:\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKFgVNSRIeNx",
        "outputId": "9cfbccd0-d64d-4542-ffc3-58bf2ce21ef0"
      },
      "source": [
        "# Have a look at an example batch from our training data loader:\n",
        "\n",
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atulf3ZEIkae",
        "outputId": "29252cf2-f9c2-48af-9c5d-b995a699fd3a"
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64])\n",
            "torch.Size([16, 64])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3p8swfQmhPw"
      },
      "source": [
        "### Sentiment Classification with ERNIE 2.0 and Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2j2-IfTIqkV"
      },
      "source": [
        "# The last_hidden_state is a sequence of hidden states of the last layer of the model. Obtaining the pooled_output is done by applying the ERNIE Pooler on last_hidden_state:\n",
        "\n",
        "last_hidden_state, pooled_output = model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JC1V_bkIyB_",
        "outputId": "a9bb4c17-e1cd-4a43-cb2a-4b6213751d8f"
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoibH_nUJWRD",
        "outputId": "151110d4-acc1-44dc-ffc0-98687bea951e"
      },
      "source": [
        "model.config.hidden_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mAOlPzZJXNz",
        "outputId": "8109f7be-22a3-41fd-d50f-2efedbd16f90"
      },
      "source": [
        "pooled_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jVm3mCJXxC"
      },
      "source": [
        "# We use all of the previous knowledge to create a sentiment classifier that uses ERNIE 2.0 model:\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.ernie = AutoModel.from_pretrained(\"nghuyong/ernie-2.0-en\", return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.ernie.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.ernie(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficDwxuCLBde"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6-nfyyfKq_9"
      },
      "source": [
        "class_names = ['anger', 'joy', 'optimism', 'sadness']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7LShQXoJfpj"
      },
      "source": [
        "# Create an instance and move it to the Colab GPU:\n",
        "\n",
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPQNWvlEK4ir",
        "outputId": "d323a033-1989-4f4c-a766-e95e7e1c4b72"
      },
      "source": [
        "# Move the example batch of our training data to the Colab GPU:\n",
        "\n",
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64])\n",
            "torch.Size([16, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFtM_A19LIPJ",
        "outputId": "dd53567b-5d7e-4a50-c480-e0f05d5be181"
      },
      "source": [
        "model(input_ids, attention_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2622, -0.7659,  0.7632, -0.7751],\n",
              "        [-0.1074, -0.9191,  0.9946, -0.1018],\n",
              "        [-0.0641, -0.4689,  0.2587, -0.2497],\n",
              "        [-0.2423, -0.9661,  0.7990, -0.1105],\n",
              "        [-0.1892, -1.0235,  0.7822, -0.8754],\n",
              "        [-0.0686, -0.9122,  0.6589, -0.3354],\n",
              "        [-0.1418, -0.6499,  0.9299, -0.2460],\n",
              "        [ 0.2238, -0.3263,  0.5216, -0.5398],\n",
              "        [-0.0795, -0.6577,  1.1104, -0.4552],\n",
              "        [-0.0177, -0.7210,  0.8258, -0.0426],\n",
              "        [-0.2805, -0.5323,  0.6579, -0.2063],\n",
              "        [-0.6258, -0.5437,  0.7089, -0.4475],\n",
              "        [ 0.1287, -0.2433,  1.2116, -0.2359],\n",
              "        [-0.3268, -0.5060,  1.5178, -0.4791],\n",
              "        [-0.5153, -0.8710,  0.3893, -0.4794],\n",
              "        [-0.2520, -0.6038,  1.0216, -0.9364]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIastka-nXTV"
      },
      "source": [
        "### Model training\n",
        "\n",
        "Although our datasets are small, we set the hyperparameters (batch size, learning rate and number of epoch) at reasonable values in order to avoid over-fitting and to obtain high prediction accuracy. We use the AdamW optimizer provided by Hugging Face that could correct weight decay. We also use a linear scheduler with no warmup steps.\n",
        "\n",
        "- Optimizer: AdamW\n",
        "- Batch size: 16\n",
        "- Learning rate : 2e-5\n",
        "- Number of epochs: 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOKZkx1SMLbj"
      },
      "source": [
        "# Set up epochs, optimizer and scheduler:\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyXbuHUfTmSO"
      },
      "source": [
        "# A helper function for training our model for one epoch:\n",
        "\n",
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNgWx_kFTNaF"
      },
      "source": [
        "# Another helper function that helps us evaluate the model on a given data loader:\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mF5T6H4T4qN",
        "outputId": "8801e866-edff-45e0-dd0e-21a45508bd5a"
      },
      "source": [
        "# Using those two helper functions, we can write our training loop. We'll also store the training history:\n",
        "\n",
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.7654592191033504 accuracy 0.7120049124961622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5673791070779165 accuracy 0.7860962566844919\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.37968994915375814 accuracy 0.8710469757445503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6397520856310924 accuracy 0.8101604278074865\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.22104040525314927 accuracy 0.9385937979735953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.8347911847134432 accuracy 0.7994652406417112\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.12121897283142578 accuracy 0.9692968989867977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.0720429470141728 accuracy 0.7994652406417112\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08237078901455629 accuracy 0.9824992324224747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.158615170667569 accuracy 0.7860962566844919\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.043864617086536085 accuracy 0.9901750076757753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.1598842677970727 accuracy 0.7860962566844919\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.03003412843385127 accuracy 0.9932453177770956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.236690603196621 accuracy 0.7941176470588235\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.019506670499514954 accuracy 0.9957015658581517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.339086126536131 accuracy 0.7941176470588235\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.01186028362794519 accuracy 0.9969296898986798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.433973881105582 accuracy 0.7941176470588235\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.010762944256152967 accuracy 0.9969296898986798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.441763414690892 accuracy 0.7914438502673796\n",
            "\n",
            "CPU times: user 4min 24s, sys: 3min 2s, total: 7min 26s\n",
            "Wall time: 7min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "YqjE6UBaUD0g",
        "outputId": "6e75d118-c4e1-48a9-9a8c-024744fa2f45"
      },
      "source": [
        "# Plot the training accuracy and validation accuracy of each epoch:\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history (Emotion Recognition')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIMAdCz4pfas"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS3w26Ooim-_",
        "outputId": "38745e18-e565-4476-af51-d42fd43acc7e"
      },
      "source": [
        "# Calculating the accuracy on the test set:\n",
        "\n",
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8191414496833216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775k6ZTalu2-"
      },
      "source": [
        "# Define a helper function to get the predictions from our model:\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  tweet_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"tweet_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      tweet_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(targets)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return tweet_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In4t-Tc3mF4O",
        "outputId": "c4230958-bf84-4af2-a8f2-be9e33e24b71"
      },
      "source": [
        "# Storing the text of tweets and predicted probabilities:\n",
        "\n",
        "y_tweet_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAWZwMjjmIbM",
        "outputId": "bdfc329c-91a6-4b97-d52e-d80941043860"
      },
      "source": [
        "# Print the classification report:\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.86      0.87      0.86       558\n",
            "         joy       0.84      0.81      0.83       358\n",
            "    optimism       0.65      0.65      0.65       123\n",
            "     sadness       0.79      0.81      0.80       382\n",
            "\n",
            "    accuracy                           0.82      1421\n",
            "   macro avg       0.79      0.79      0.79      1421\n",
            "weighted avg       0.82      0.82      0.82      1421\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "_RLU8dE9mUrI",
        "outputId": "f01026cf-308b-4152-dcb6-6930b8ae1e19"
      },
      "source": [
        "# Plot the confusion matrix:\n",
        "\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment (Emotion Recognition)');\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hQTQaecmYuA"
      },
      "source": [
        "# Check an example tweet from the test set:\n",
        "\n",
        "idx = 2\n",
        "tweet_text = y_tweet_texts[idx]\n",
        "true_sentiment = y_test[idx]\n",
        "pred_df = pd.DataFrame({\n",
        "  'class_names': class_names,\n",
        "  'values': y_pred_probs[idx]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXS_1enbmfWX",
        "outputId": "f1e4021d-66e5-43ab-c003-7cb04b13e7a6"
      },
      "source": [
        "print(\"\\n\".join(wrap(tweet_text)))\n",
        "print()\n",
        "print(f'True sentiment: {class_names[true_sentiment]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My visit to hospital for care triggered #trauma from accident 20+yrs\n",
            "ago and image of my dead brother in it. Feeling symptoms of\n",
            "#depression\n",
            "\n",
            "True sentiment: sadness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "1Bk3_bfpoKlQ",
        "outputId": "047ea7d6-7f31-4854-a5f9-f785fc50b899"
      },
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
        "plt.ylabel('sentiment')\n",
        "plt.xlabel('probability')\n",
        "plt.xlim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyGgOJhRovY-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}